Clases de complejidad algoritmica

O(1) Constante
O(n) Lineal
O(log n) Logaritmica
O(n log n) Log lineal
O(n**2) Polinomial
O(2**n) Exponencial


-Crear entorno virtual

python3 -m venv venv


-activar entorno virtual
source venv/Scripts/activate

- Actualizar el manejador de paquetes pip

python -m pip install pip --upgrade


-instalar librerias

pip install bokeh

-para ver que tiene instalado

pip freeze

-salir del entorno virtual 

deactivate

-ver errores de tipos de datos

mypy Palindrome_using_static_typing.py --check-untyped-defs



SETS----------------------------
add
Adds a specified element to the set.
update
Adds specified elements to the set.
Deleting
discard
Removes an element from the set.
remove
Removes an element from the set (raises KeyError if not found).
pop
Removes and returns an arbitrary element from the set.
clear
Removes all elements from the set.

Set Operations
- (difference)
Returns a new set with elements in the set that are not in the other set.
& (intersection)
Returns a new set with elements common to the set and the other set.
^ (symmetric_difference)
Returns a new set with elements in either the set or the other set but not both.
| (union)
Returns a new set with elements from the set and the other set.

formatos de hora
import datetime
%Y =año
%m mes
%d dia
%H hora
%M mes
%S segundos


______________Scrapping

instalar paquetes para hacer scrapping

pip install requests lxml autopep8

___________Scrapy ----------------------

- instalar scrapy y autopep8

pip install scrapy autopep8

-para comprovar si quedó bien instalado

scrapy version 


- iniciar proyecto

 scrapy startproject tutorial       tutorial es el nombre

- nos movemos dentro de la carpeta de proyecto (tutorial)

-ejecutar scripts con scrapy (ejecuta el programa)

 scrapy crawl quotes          - quotes es el nombre del spider (clase) (ejecuta el proyecto)

-para tomar de referencia la pagina en la que se va a trabajar (abrir entorno)

scrapy shell 'http://quotes.toscrape.com/'

-trae lo que esta en esa posicion de la etiqueta

response.xpath('//h1/a/text()').get()

- getall() sirve para traer listas

response.xpath('//span[@class="text" and @itemprop="text"]/text()').getall()




response.xpath('//a[@class="mobile-header-title expandable"]/div/text()').getall()
response.xpath('//div[contains(@class, "tags-box")]//span[@class="tag-item"]/a/text()').getall()

- guarda los datos solicitados (-o salida) en un archivo "nombre".json
scrapy crawl quotes -o quotes.json


/OneDrive/Desktop/Platzi/Python/CursoPython_inter/python-programs/Scrapy_Course/tutorial

- Proyecto scraper Quotes
/OneDrive/Desktop/Platzi/Python/CursoPython_inter/python-programs/Scrapy_Course/quotes_scraper/quotes_scraper 



- para mostrar unicamente el top 5 de tags
scrapy crawl quotes -a top=5


-shift+alt+f para organizar todo el texto

- CONFIGURACIONES:

'CONTURRENT_REQUESTS': 24 #permite realizar (24) peticiones a la vez
'MEMUSAGE_LIMIT_MB': 2048, # Cantidad de memoria Ram que se le permite a scrapy utilizar
'MEMUSAGE_NOTIFY_MAIL':['leonardorm7@hotmail.com'] #si se supera la cantidad de memoria ram usada, se enviará una alerta al correo
'ROBOTSTXT_OBEY': True, #obedece las reglas del archivo robots.txt
'USER_AGENT': 'Leonardo Rodriguez' # en el servidor, aparecerá que esta persona hizo la peticion.
'FEED_EXPORT_ENCODING': 'utf-8' # para que no se obtengan caracteres raros en nuestro archivo Json




response.xpath('//a[starts-with(@href,"collection") and (parent::h3|parent::h2)]/@href').getall()

grades
response.xpath('//div[@id="main"]//div[@class="viewport_1 slick-viewport"]//span[@class="Grade"]/text()').get()
response.xpath('//div[@class="viewport_0 slick-viewport"]//a[@class="student-grades-link student_context_card_trigger"]/text()').getall()
response.xpath('//div[@class="assignment-gradebook-container"]//span[@class="fCrpb_bGBk fCrpb_egrg"]/text()').getall()
visualizar en xhtml
x('//div[@class="viewport_0 slick-viewport"]//a[@class="student-grades-link student_context_card_trigger"]/text()').map(x=>x.wholeText)


- registrar la url del repositorio en el folder
git remote add origin git@github.com:Engleonardorm7/Intellig

-Añadir todos los archivos
git add -A

-permitir unir los documentos que estan en la carpeta de Github con la carpeta de nuestro documento
git pull origin main --allow-unrelated-histories

Un nodo div con una clase que contiene “tags-box” en su contenido se selecciona mediante la siguiente expresión de XPath:

//div[contains(@class, "tags-box")]

